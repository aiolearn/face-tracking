<h1 align="center">Welcome to Face Tracking Project ğŸ‘‹</h1>

# Face Tracking

In this project, we have written a face and eye recognition program with Python

## Modules

```python
import cv2
import pyautogui as robot
```

## Usage
Loading eye and face recognition model

```python
eye_model = cv2.CascadeClassifier('haarcascade_eye.xml')
face_model = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
loop = True
```

Activating the camera and horizontalizing the image and face detection in the image and eye detection in the face image

```python
cam = cv2.VideoCapture(0)

while loop:
    _ , img = cam.read()
    
    img = cv2.flip(img, 1)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    face = face_model.detectMultiScale(gray)
    
    if len(face) > 0:
        xs = face[0][0]
        ys = face[0][1]
        xs2 = xs + face[0][2]
        ys2 = ys + face[0][3]
        gray_face = gray[ys:ys2,xs:xs2]
        eye = eye_model.detectMultiScale(gray_face, minSize = (30,30), scaleFactor=1.1, minNeighbors=5)
        imgout = img.copy()
```
Draw a rectangle around the face

```python
out = cv2.rectangle(imgout, (xs,ys),(xs2,ys2),(0,250,0),3)
    
    white = (250,250,250)
    red = (0,0,250)
    rang = white
    
    mouse_x = robot.position().x
    mouse_y = robot.position().y

    if xs < 400:
        rang = red
        mouse_x -= abs(xs-400)
        robot.moveTo(mouse_x, mouse_y, 0)
    
    if xs2 > 900:
        rang = red
        mouse_x += abs(xs2 - 900)
        robot.moveTo(mouse_x, mouse_y, 0)

    if ys < 100:
        rang = red
        mouse_y -= abs(ys - 100)
        robot.moveTo(mouse_x, mouse_y, 0)

    if ys2 > 600:
        rang = red
        mouse_y += abs(ys2 - 600)
        robot.moveTo(mouse_x, mouse_y, 0)
```

Draw a border rectangle for mouse movement

```python
out = cv2.rectangle(imgout, (400,100),(900,600),rang,2)

    ic = 0
    for (xe, ye, w, h) in eye:
        ic += 1
        cv2.rectangle(imgout,(xe+xs, ye+ys), (xe+w+xs, ye+h+ys),(250,0,0),2)
        if ic == 2:
            break
    
    cv2.imshow('out',out)

    if cv2.waitKey(1) == ord('q'):
        loop = False
        cv2.destroyAllWindows()
        cam.release()
        break

robot.moveTo(0,0,0.5)
```
Get the current position of the mouse and print it

```python
po = robot.position()
print(po.x)
```

## Result

This project was written by Majid Tajanjari and the Aiolearn team, and we need your support!â¤ï¸

# ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡

Ø¯Ø± Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø±Ù†Ø§Ù…Ù‡ ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡ Ùˆ Ú†Ø´Ù… Ø¨Ø§ Ù¾Ø§ÛŒØªÙˆÙ† Ù†ÙˆØ´ØªÙ‡ Ø§ÛŒÙ…

## Ù…Ø§Ú˜ÙˆÙ„ Ù‡Ø§

```python
import cv2
import pyautogui as robot
```

## Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡
Ù„ÙˆØ¯ÛŒÙ†Ú¯ Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡ Ùˆ Ú†Ø´Ù…

```python
eye_model = cv2.CascadeClassifier('haarcascade_eye.xml')
face_model = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
loop = True
```

ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø¯ÙˆØ±Ø¨ÛŒÙ† Ùˆ Ø§ÙÙ‚ÛŒ Ú©Ø±Ø¯Ù† ØªØµÙˆÛŒØ± Ùˆ ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡ Ø¯Ø± ØªØµÙˆÛŒØ± Ùˆ ØªØ´Ø®ÛŒØµ Ú†Ø´Ù… Ø¯Ø± ØªØµÙˆÛŒØ± Ú†Ù‡Ø±Ù‡

```python
cam = cv2.VideoCapture(0)

while loop:
    _ , img = cam.read()
    
    img = cv2.flip(img, 1)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    face = face_model.detectMultiScale(gray)
    
    if len(face) > 0:
        xs = face[0][0]
        ys = face[0][1]
        xs2 = xs + face[0][2]
        ys2 = ys + face[0][3]
        gray_face = gray[ys:ys2,xs:xs2]
        eye = eye_model.detectMultiScale(gray_face, minSize = (30,30), scaleFactor=1.1, minNeighbors=5)
        imgout = img.copy()
```
Ø±Ø³Ù… Ù…Ø³ØªØ·ÛŒÙ„ Ø¯ÙˆØ± Ú†Ù‡Ø±Ù‡

```python
out = cv2.rectangle(imgout, (xs,ys),(xs2,ys2),(0,250,0),3)
    
    white = (250,250,250)
    red = (0,0,250)
    rang = white
    
    mouse_x = robot.position().x
    mouse_y = robot.position().y

    if xs < 400:
        rang = red
        mouse_x -= abs(xs-400)
        robot.moveTo(mouse_x, mouse_y, 0)
    
    if xs2 > 900:
        rang = red
        mouse_x += abs(xs2 - 900)
        robot.moveTo(mouse_x, mouse_y, 0)

    if ys < 100:
        rang = red
        mouse_y -= abs(ys - 100)
        robot.moveTo(mouse_x, mouse_y, 0)

    if ys2 > 600:
        rang = red
        mouse_y += abs(ys2 - 600)
        robot.moveTo(mouse_x, mouse_y, 0)
```

Ø±Ø³Ù… ÛŒÚ© Ù…Ø³ØªØ·ÛŒÙ„ Ø­Ø§Ø´ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø­Ø±Ú©Øª Ù…Ø§ÙˆØ³

```python
out = cv2.rectangle(imgout, (400,100),(900,600),rang,2)

    ic = 0
    for (xe, ye, w, h) in eye:
        ic += 1
        cv2.rectangle(imgout,(xe+xs, ye+ys), (xe+w+xs, ye+h+ys),(250,0,0),2)
        if ic == 2:
            break
    
    cv2.imshow('out',out)

    if cv2.waitKey(1) == ord('q'):
        loop = False
        cv2.destroyAllWindows()
        cam.release()
        break

robot.moveTo(0,0,0.5)
```
Ø±Ø³Ù… Ù…ÙˆÙ‚Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ù…Ø§ÙˆØ³ Ùˆ  Ú†Ø§Ù¾

```python
po = robot.position()
print(po.x)
```

## Ù†ØªÛŒØ¬Ù‡

Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ØªÙˆØ³Ø· Ù…Ø¬ÛŒØ¯ ØªØ¬Ù† Ø¬Ø§Ø±ÛŒ Ùˆ ØªÛŒÙ… Aiolearn Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª Ùˆ Ù…Ø§ Ø¨Ù‡ Ø­Ù…Ø§ÛŒØª Ø´Ù…Ø§ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒÙ…!â¤ï¸